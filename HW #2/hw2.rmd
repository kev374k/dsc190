---
title: "Homework #1"
author: "Kevin Wong"
date: "2024-10-07"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Data Cleaning

```{r, echo = FALSE}
survey_p1 <- read.table("videodata.txt", header = TRUE)
survey_p2 <- read.table("videoMultiple.txt", header = TRUE)
```

```{r, echo = FALSE}
head(survey_p1, 5)
head(survey_p2, 5)
```

```{r, echo = FALSE}
str(survey_p1)
str(survey_p2)
```

Through this, we notice that the all of the columns in our first dataset are numbers/integers, which is correct. However, for our second dataset, our variables are mostly ints which make sense, but there are two extra columns, 'other' and 'other2' are present but are not in the second part of the survey. This means that there might be a discrepancy in the data, because it should be numeric, even though it isn't. Let's create a function to detect non-numeric columns, and show us them.

```{r}
survey_p2 <- survey_p2[, !(names(survey_p2) %in% c("other", "other2"))]
all(sapply(survey_p2, is.numeric))
```

```{r}
rows_with_all_zeros <- apply(survey_p2, 1, function(row) all(row == 0))
survey_p2[rows_with_all_zeros, ]
```

In order to further clean the data, we are going to combine the tables together and merge them in order to create one large table. For this, we are going to go with the assumption that each row in both tables represents the same person, since each student was assigned a unique number.

```{r, echo = FALSE}
combined_table <- cbind(survey_p1, survey_p2)
head(combined_table, 5)
```

Below is a table showing all rows that contain at least one NA value. As we can see, NA values only exist in the variables from the part 2 survey.

```{r, echo = FALSE}
combined_table[apply(is.na(combined_table), 1, any), ]

```

Now, let's get rid of rows that contain NA values, just to get rid of inconsistent data.

```{r, echo = FALSE}
cleaned_df <- na.omit(combined_table)
dim(cleaned_df)
```

Looking through this, we had 4 rows that contained NA values, so now we only have 87 rows left.

Notes: 1) busy, educ, sex, home, math, own, cdrom, email, action, adv, sim, sport, strategy, graphic, relax, coord, challenge, bored, time, frust, lonely, rules, cost, boring, friends, point are binary, so their distributions will be concentrated at 0 and 1 2) time, age, and work are continuous variables, may be similar to a normal distribution 3) like, freq, and grade are categorical, ordinal variables 4) where is a nominal variable 5) 99 shouldn't be included in the data

```{r}
for (col in names(cleaned_df)) {
    valid_data <- cleaned_df[[col]][cleaned_df[[col]] != 99]

    if (length(valid_data) > 0) {
        hist(valid_data, main = paste("Histogram of", col), xlab = col, breaks=30)
    } else {
        message(paste("No valid data for column", col))
    }
}
```

Looking through the histograms, there are multiple values that are coded as 99 because students left some questions unaswered or improperly answered. This means that when we filter the data, we need to make sure that the data that we get don't include the non-responses

# 1

In order to provide a solid estimation of the amount of people who played a video game in the week prior to the survey, let's filter the amount of people who had over 0 hours last week as well as get rid of the people who didn't respond to the prompt (99)

```{r, echo = FALSE}
n_played <- nrow(cleaned_df[cleaned_df$time > 0 | cleaned_df$time == 99, ])
n_total <- nrow(cleaned_df)

point_estimate_fraction <- n_played / n_total
print(paste("Point Estimate: ", round(point_estimate_fraction, 4)))
```

Now, let's use a 95% confidence interval to construct an interval estimate for this proportion

```{r, echo = FALSE}
confidence_level = 0.95
z <- qnorm((1 + confidence_level) / 2)

se <- sqrt(point_estimate_fraction * (1 - point_estimate_fraction) / n_total)

lower_interval_estimate_fraction <- point_estimate_fraction - z * se
upper_interval_estimate_fraction <- point_estimate_fraction + z * se
print(paste("95% Confidence Interval: [", round(lower_interval_estimate_fraction, 4), ", ", round(upper_interval_estimate_fraction, 4), "]", sep = ""))
```

The distinction between the point estimate and the interval estimate is that they serve different purposes in statistical inference. For instance, a point estimate is a value that provides the best guess/estimate for a population parameter. On the other hand, an interval estimate is an estimate that provides a range of values where the true population parameter is expected to lie in, and specifically in this case, with a 95% confidence. Point Estimates are simple and provide a direct measurement, while intervals are more uncertain, but are more robust as data scales up.

# 2

First, in order to determine the amount of time someone spent playing video games, we should look at the 'time' column as well as the 'freq' column so we can compare the two values. In order to determine

```{r, echo = FALSE}
actual_values = cleaned_df[cleaned_df$time != 99 & cleaned_df$freq != 99, ]
avg_time <- tapply(actual_values$time, actual_values$freq, mean, na.rm = TRUE)
median_time <- tapply(actual_values$time, actual_values$freq, median, na.rm = TRUE)
count <- table(actual_values$freq)

summary <- data.frame(
    frequency = names(avg_time),
    avg_time = as.vector(avg_time),
    median_time = as.vector(median_time),
    count = as.vector(count)
)
summary

boxplot(time ~ freq,
        data = actual_values,
        xlab = "Frequency of Play (1 = Daily, 2 = Weekly, 3 = Monthly, 4 = Semesterly",
        ylab = "Hours Played",
        main = "Reported Frequency of Play and Hours Played During Exam Week"
        )
```

This time let's filter for exam week. One assumption that we made regarding this is that students were more likely to study instead of game for the week, so for the next visualization, let's ignore students who reported 0 hours of gaming in the previous week.

```{r, echo = FALSE}
exam_adjusted_df <- actual_values[actual_values$time != 0, ]
avg_time_adj <- tapply(exam_adjusted_df$time, exam_adjusted_df$freq, mean, na.rm = TRUE)
median_time_adj <- tapply(exam_adjusted_df$time, exam_adjusted_df$freq, median, na.rm = TRUE)
count_adj <- table(exam_adjusted_df$freq)

exam_adj_summary <- data.frame(
    frequency = names(avg_time_adj),
    avg_time = as.vector(avg_time_adj),
    median_time = as.vector(median_time_adj),
    count = as.vector(count_adj)
)

exam_adj_summary

boxplot(time ~ freq, 
        data = exam_adjusted_df,
        xlab = "Frequency of Play (1 = Daily, 2 = Weekly, 3 = Monthly, 4 = Semesterly",
        ylab = "Hours Played",
        main = "Reported Frequency of Play and Hours Played"
        )
```

Looking through these two boxplots and their data summaries, there is an obvious difference, especially for students with a daily or weekly frequency of play. For instance, our adjusted comparison shows that those who played ('freq' = 1) daily during an exam week typically had a lower amount of hours played, with a 1.5 hour difference between our exam week data and our filtered data. Similarly, our boxplot also shows a difference in the interquartile range between the two datasets for those who played daily, as during a normal week, students were more likely to play more and had a wider variety of playtimes, which can be inferred from the two box plots. A similar comparison can be made from students who played weekly ('freq' = 2). There's a \~0.4 hour increase in normal weeks versus the exam week. Another interesting observation is that the adjusted data seems to have a smaller interquartile range compared to it's original exam week data, somewhat implying that those who play weekly usually play a more set amount of hours that usually doesn't diverge. Frequencies 3 and 4 don't have a large difference, just due to the nature of their descriptions. If someone only plays games monthly or semesterly, then they are less likely to have major differences during an exam week versus a normal week. Overall, the fact that there was an exam in the week prior to the survey tells us this:

-   On average, students played less hours than they normally would on a week without an exam
-   Those who reported that they play daily or weekly typically have the largest difference between their average hours played during an exam versus a normal week
-   Those who reported that they play monthly or semesterly have small or negligible differences between their average hours played due to the nature and scarcity of their data.

# 3

The point estimate for the average amount of time spent playing video games in the week prior to the survey is simply the sample mean. We will also calculate the standard error (SE) to represent the expected variability of our sample mean from the true population mean of time spent playing video games. This SE will also be used to construct our 95% confidence interval. The SE formula must use the **population correction factor** because we are sampling **without replacement** from a relatively small population of 314. $$SE = {Ïƒ \over \sqrt{n}} \times \sqrt{N-n \over N - 1}$$

```{r}
point_estimate_average <- mean(survey_p1$time, na.rm=TRUE)
N <- 314
n <- length(survey_p1$time)

sample_sd <- sd(survey_p1$time, na.rm = TRUE)
pop_correction_factor = sqrt((N - n) / (N - 1))
standard_error <- (sample_sd / sqrt(n)) * pop_correction_factor

print(paste("point_estimate_average:", point_estimate_average))
print(paste("Standard Error:", standard_error))
```

Construct the 95% Confidence Interval.

```{r}
alpha <- 0.05
z_value <- qnorm(1 - alpha / 2)

lower_interval_estimate_average <- point_estimate_average - z_value * standard_error
upper_interval_estimate_average <- point_estimate_average + z_value * standard_error

print(paste("lower_interval_estimate_average:", lower_interval_estimate_average))
print(paste("upper_interval_estimate_average:", upper_interval_estimate_average))
```

Next, we perform a bootstrap simulation to estimate the sampling distribution of average time spent playing games. If this estimated sampling distribution is approximately normal, then our confidence interval is appropriate, but if it's not normal, then the approach taken is not appropriate.

```{r}
library(boot)

# Calculate the sample mean for each bootstrapped sample
bootstrap_mean <- function(data, indices) {
  return(mean(data[indices], na.rm = TRUE))
}

# Perform bootstrapping with 1000 iterations
bootstrap_results <- boot(survey_p1$time, bootstrap_mean, R = 1000)
bootstrap_means <- bootstrap_results$t
```

Now, I construct another 95% confidence interval using the percentiles of my bootstrapped sample means and compare it to the earlier confidence interval which was constructed using the point estimate and an assumption of a normal distribution. If they are significantly different, the interval estimate may not be appropriate for this situation.

```{r}
bootstrap_ci <- boot.ci(bootstrap_results, type = "perc")

# Extract lower and upper bounds of the 95% Bootstrap CI
lower_bound_bootstrap <- bootstrap_ci$percent[4]
upper_bound_bootstrap <- bootstrap_ci$percent[5]

hist(bootstrap_means, main = "Bootstrap Sample Means with 95% CIs", 
     xlab = "Sample Mean Time Spent", 
     col = "lightblue", 
     border = "black", 
     probability = TRUE)

# Add vertical lines for the confidence intervals
abline(v = lower_bound_bootstrap, col = "red", lwd = 2, lty = 2)  # Lower CI bound
abline(v = upper_bound_bootstrap, col = "red", lwd = 2, lty = 2)  # Upper CI bound
abline(v = lower_interval_estimate_average, col = "blue", lwd = 2, lty = 1)
abline(v = upper_interval_estimate_average, col = "blue", lwd = 2, lty = 1)


legend("topright", legend = c("Lower Bootstrap CI", "Upper Bootstrap CI", "Lower 95% CI", "Upper 95% CI"),
       col = c("red", "red", "blue", "blue"), lty = c(2, 2, 1, 1), lwd = 2)
```

# 4

First, to get an idea of whether students generally like playing video games or not, we can examine a bar plot of the "like" variable.

```{r, echo = FALSE}
like_counts <- table(subset(survey_p1, like != 99)$like)

# Plot the bar plot
barplot(like_counts, 
        main = "Counts of Responses to 'Like to Play' Video Games", 
        xlab = "Response Category", 
        ylab = "Count of Students", 
        col = "lightblue", 
        border = "black", 
        names.arg = c("Never Played", "Very Much", "Somewhat", "Not Really", "Not At All"))
```

Additionally, we can calculate the proportion of students surveyed that at least somewhat like playing video games.

```{r, echo = FALSE}
total_students <- length(survey_p1$like[survey_p1$like != 99])
students_like <- length(survey_p1$like[survey_p1$like == 2 | survey_p1$like == 3])

proportion_like <- students_like / total_students
print(paste("Proportion of students in sample who at least somewhat like video games:", proportion_like))
```

Now, to find the most influential reasons for why students like or dislike playing video games, we use a bar plot to visualize the frequency of each reason.

```{r, echo = FALSE}
reason_frequencies <- colSums(na.omit(survey_p2)[, !names(survey_p2) %in% c("action","adv","sim","sport","strategy")])

bar_colors <- c("relax" = "lightblue", 
                "coord" = "lightblue", 
                "challenge" = "lightblue", 
                "master" = "lightblue", 
                "bored" = "lightblue", 
                "graphic" = "lightblue",
                "time" = "red",
                "frust" = "red",
                "lonely" = "red",
                "rules" = "red",
                "cost" = "red",
                "boring" = "red",
                "friends" = "red",
                "point" = "red")

barplot(reason_frequencies, 
        main = "Frequencies of Reasons for Liking/Disliking Video Games",
        ylab = "Frequency", 
        col = bar_colors[names(reason_frequencies)], 
        border = "black", 
        las = 2)
```

The most important reason for why students like video games is for relaxation. The most important reasons why students don't like video games are that they're time-consuming, costly, and pointless.

```{r, echo = FALSE}
reasons_for_likeliness <- c("relax", "time", "cost", "point")
print("Reasons for Like/Dislike Video Games:")
print(reasons_for_likeliness)
```

# 5

To understand the differences between those who like to play video games and those who don't, we first collapse the range of responses to the last questions into 2 or 3 responses per question rather than 6 or 7. The responses to the question "Why do you play video games?" were placed into 2 categories: "Entertainment" and "Mental Engagement". The responses to the question "Why don't you like playing video games?" were placed into 3 categories: "Difficulty", "Low Priority", and "Isolation".

```{r, echo = FALSE}
clean_p2 <- cleaned_df

clean_p2$Entertainment <- clean_p2$graphic | clean_p2$relax | clean_p2$bored
clean_p2$Mental_Engagement <- clean_p2$coord | clean_p2$challenge | clean_p2$master
clean_p2$Difficulty <- clean_p2$frust | clean_p2$rules
clean_p2$Low_Priority <- clean_p2$time | clean_p2$cost | clean_p2$boring | clean_p2$point
clean_p2$Isolation <- clean_p2$lonely | clean_p2$friends

clean_p2 <- clean_p2[, c("sex", "work", "own", "Entertainment","Mental_Engagement","Difficulty","Low_Priority","Isolation")]
clean_p2[clean_p2 == 99] <- NA
clean_p2$work <- clean_p2$work > 0
clean_p2 <- na.omit(clean_p2)
```

Next, we make cross-tabulations to show how various factors for liking or disliking video games change between different groups of people.

```{r, echo = FALSE}
sex_cross_tab_1 <- table(clean_p2$Entertainment, clean_p2$sex)
dimnames(sex_cross_tab_1) <- list(
  "Entertainment" = c("No", "Yes"),
  "Sex" = c("Female", "Male")
)

sex_cross_tab_2 <- table(clean_p2$Mental_Engagement, clean_p2$sex)
dimnames(sex_cross_tab_2) <- list(
  "Mental Engagement" = c("No", "Yes"),
  "Sex" = c("Female", "Male")
)

sex_cross_tab_3 <- table(clean_p2$Difficulty, clean_p2$sex)
dimnames(sex_cross_tab_3) <- list(
  "Difficulty" = c("No", "Yes"),
  "Sex" = c("Female", "Male")
)

sex_cross_tab_4 <- table(clean_p2$Isolation, clean_p2$sex)
dimnames(sex_cross_tab_4) <- list(
  "Isolation" = c("No", "Yes"),
  "Sex" = c("Female", "Male")
)

cat("Cross-Tabulation: Sex vs Entertainment\n\n")
print(sex_cross_tab_1)

cat("\n\nCross-Tabulation: Sex vs Mental Engagement\n\n")
print(sex_cross_tab_2)

cat("\n\nCross-Tabulation: Sex vs Difficulty\n\n")
print(sex_cross_tab_3)

cat("\n\nCross-Tabulation: Sex vs Isolation\n\n")
print(sex_cross_tab_4)
```

```{r, echo = FALSE}
cross_tab_1 <- table(clean_p2$Entertainment, clean_p2$work)
dimnames(cross_tab_1) <- list(
  "Entertainment" = c("No", "Yes"),
  "Works" = c("No", "Yes")
)

cross_tab_2 <- table(clean_p2$Mental_Engagement, clean_p2$work)
dimnames(cross_tab_2) <- list(
  "Mental Engagement" = c("No", "Yes"),
  "Works" = c("No", "Yes")
)

cross_tab_3 <- table(clean_p2$Difficulty, clean_p2$work)
dimnames(cross_tab_3) <- list(
  "Difficulty" = c("No", "Yes"),
  "Works" = c("No", "Yes")
)

cross_tab_4 <- table(clean_p2$Low_Priority, clean_p2$work)
dimnames(cross_tab_4) <- list(
  "Low Priority" = c("No", "Yes"),
  "Works" = c("No", "Yes")
)

cat("Cross-Tabulation: Works vs Entertainment\n\n")
print(cross_tab_1)

cat("\n\nCross-Tabulation: Works vs Mental Engagement\n\n")
print(cross_tab_2)

cat("\n\nCross-Tabulation: Works vs Difficulty\n\n")
print(cross_tab_3)

cat("\n\nCross-Tabulation: Works vs Low Priority\n\n")
print(cross_tab_4)
```

```{r, echo = FALSE}
own_cross_tab_1 <- table(clean_p2$Entertainment, clean_p2$own)
dimnames(own_cross_tab_1) <- list(
  "Entertainment" = c("No", "Yes"),
  "Owns PC" = c("No", "Yes")
)

own_cross_tab_2 <- table(clean_p2$Mental_Engagement, clean_p2$own)
dimnames(own_cross_tab_2) <- list(
  "Mental Engagement" = c("No", "Yes"),
  "Owns PC" = c("No", "Yes")
)

own_cross_tab_3 <- table(clean_p2$Difficulty, clean_p2$own)
dimnames(own_cross_tab_3) <- list(
  "Difficulty" = c("No", "Yes"),
  "Owns PC" = c("No", "Yes")
)

own_cross_tab_4 <- table(clean_p2$Isolation, clean_p2$own)
dimnames(own_cross_tab_4) <- list(
  "Isolation" = c("No", "Yes"),
  "Owns PC" = c("No", "Yes")
)

cat("Cross-Tabulation: Owns PC vs Entertainment\n\n")
print(own_cross_tab_1)

cat("\n\nCross-Tabulation: Owns PC vs Mental Engagement\n\n")
print(own_cross_tab_2)

cat("\n\nCross-Tabulation: Owns PC vs Difficulty\n\n")
print(own_cross_tab_3)

cat("\n\nCross-Tabulation: Owns PC vs Isolation\n\n")
print(own_cross_tab_4)
```

The most notable cross-tabulations are those comparing "Sex vs Entertainment", "Works vs Mental Engagement", and "Owns PC vs Entertainment". We found the most notable comparisons by generating every single cross-tabulation possible and choosing the ones where the distribution of responses changed the most from one group to the next. To analyze these comparisons further, we produce grouped bar plots.

```{r, echo = FALSE}
barplot(sex_cross_tab_1, beside = TRUE, 
        col = c("red", "lightblue"),
        legend = rownames(sex_cross_tab_1),
        main = "Gender vs Enjoys Entertainment",
        xlab = "Enjoys Entertainment Aspect", 
        ylab = "Count")

```

```{r, echo = FALSE}
barplot(cross_tab_2, beside = TRUE,
        col = c("red", "lightblue"),
        legend = rownames(cross_tab_2),
        main = "Works vs Enjoys Mental Challenge",
        xlab = "Enjoys Mental Engagement Aspect",
        ylab = "Count")

```

```{r, echo = FALSE}
barplot(own_cross_tab_1, beside = TRUE,
        col = c("red", "lightblue"),
        legend = rownames(own_cross_tab_1),
        main = "Owns PC vs Enjoys Entertainment",
        xlab = "Enjoys Entertainment Aspect",
        ylab = "Count")
```

# Advanced Analysis

Our advanced analysis focuses on the intersectionality between people that like video games and which types of video games they prefer. By doing this, we can see the most popular types of video games that these students prefer, along with the average amount of time they play video games a week, potentially showing us which games people spent the most time on.

First, we filter the data. It's important to note that we ignore people who skipped this question, because the instructions state that those who disliked video games were instructed to do so.

```{r, echo = FALSE}
video_games_data <- cleaned_df[!(cleaned_df$action == 0 & cleaned_df$adv == 0 & cleaned_df$sim == 0 & cleaned_df$sport == 0 & cleaned_df$strategy == 0), ]
dim(video_games_data)
```

Now, let's capture the most popular video game types from this data.

```{r, echo = FALSE}
freq_table <- colSums(video_games_data[, c("action", "adv", "sim", "sport", "strategy")] == 1)
barplot(freq_table, main = "Video Game Popularity by Genre", xlab = "Genre", ylab = "Frequency", col = "blue")
```

Now, let's compare the amount of time people spent playing these games.

```{r, echo = FALSE}
action_time <- sum(cleaned_df$time[cleaned_df$action == 1], na.rm = TRUE)
adv_time <- sum(cleaned_df$time[cleaned_df$adv == 1], na.rm = TRUE)
sim_time <- sum(cleaned_df$time[cleaned_df$sim == 1], na.rm = TRUE)
sport_time <- sum(cleaned_df$time[cleaned_df$sport == 1], na.rm = TRUE)
strategy_time <- sum(cleaned_df$time[cleaned_df$strategy == 1], na.rm = TRUE)

summed_times <- c(
    action_time,
    adv_time,
    sim_time,
    sport_time,
    strategy_time
)
names(summed_times) <- c("action", "adv", "sim", "sport", "strategy")

barplot(summed_times,
        main = "Total Time Spent on Each Game Category",
        xlab = "Game Category",
        ylab = "Total Time", 
        col = "lightblue",
        las = 2
        )
```

Our two graphs, especially when put next to each other, show us another interesting detail. Although strategy was the most popular game genre chosen by people, with the action and sport genres falling slightly behind, when we look through the total time spent playing each game, action was the highest, with sport and then strategy falling behind. This means that there's a decent chance that the people who play strategy games don't typically play the game for a longer time, while those who played action and sports games play for longer durations. On another note, sim was the least popular genre of game in the survey, and that pattern still shows in the total time spent. People who mentioned they like simulation games spent very little time actually playing them, leading us to believe that those who play these simulation games either don't play them very often or play them for short periods of time compared to their peers who played action or sport games.

Of course, this is not a conclusive study. Firstly, there's inherent bias because this survey was taken during an exam week, likely leading to students playing less than they normally would. Additionally, the way we filtered our data may be potentially flawed, as students were allowed to choose up to 3 of their favorite genres, not just one. This means that our graph of total time spent on each category is layered and can be duplicated, because if a student likes to play multiple genres of games, they are stacked on top of their respective genres, potentially leading to more visible and exaggerated graphs than what would normally be. However, even with that discrepancy, we still believe that these two graphs show us concrete differences in many of the genres and how students viewed the genres differently, both in terms of popularity as well as personal enjoyment.
