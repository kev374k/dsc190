---
title: "Gaming Patterns in Higher Education"
author: "Author 1 and Author 2"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Header

## Author Contributions

Author 1: Did the data cleaning and preliminary analysis, as well as contributed to questions #1 and #2, along with doing the advanced data analysis.

Author 2: Contributed to additional data cleaning and analysis for questions 3, 4, and 5.

## Use of GPT

ChatGPT was used as a substitute for documentation for R. Since we were unfamiliar with R, we asked ChatGPT how to use R in certain methods in order to find and filter out conditions in the dataset. We additionally used GPT to analyze reasoning and to confirm what we thought was correct about the dataset, as well as to identify extra questions that could be answered for our advanced analysis.

# Introduction

The data provided is from a survey done at UC Berkeley for students enrolled in a statistics course in 1994. Out of an eligible 314 students, 91 students submitted eligible responses which will be the data used in this EDA. The data focuses on student's play time of video games, likes and dislikes of video games, and more. One important thing to note is that responses that were left unaswered or improperly answered were coded as 99, and students who had never played video games or expressed a strong dislike for them were instructed to skip many questions. Additionally, the survey was distributed into two parts, where the first part asks about variable data, while the second part focuses on attitude questions.

## Main Research Questions

1.  Provide an estimate for the fraction of students who played a video game in the week prior to the survey.

2.  Check to see how the amount of time spent playing video games in the week prior to the survey compares to the reported frequency of play (daily, weekly, etc). How might the fact that there was an exam in the week prior to the survey affect your previous estimates and this comparison?

3.  Provide a point estimate and an interval estimate for the average amount of time spent playing video games in the week prior to the survey. Keep in mind the overall shape of the sample distribution. A simulation study may help determine the appropriateness of an interval estimate.

4.  Consider the attitude questions. In general, do you think the students enjoy playing video games? If you had to make a short list of the most important reasons why students like/dislike video games, what would you put on the list? Don’t forget that those students who say that they have never played video games or do not at all like video games are asked to skip over some of these questions. So, there may be many nonrespondents to the questions as to whether they think video games are educational, where they play video games, etc.

5.  Look for the differences between those who like to play video games and those who don’t. To do this, use the questions in the last part of the survey, and make comparisons between male and female students, those who work for pay and those who don’t, those who own a computer and those who don’t. Graphical display and cross-tabulations are particularly helpful in making these kinds of comparisons. Also, you may want to collapse the range of responses to a question down to two or three possibilities before making these comparisons.

6.  Further investigate the grade that students expect in the course. How does it match the target distribution used in grade assignment of 20% A’s, 30% B’s, 40% C’s and 10% D’s or lower? If the nonrespondents were failing students who no longer bothered to come to the discussion section, would this change the picture?

## Outline

The remainder of the report will go through a basic analysis of the data, including our cleaning methods, basic analysis on various variables in the study, and more. Additionally, we will analysis the questions posed above, along with the conclusions that we came up with in our data. We will also pose an advanced analysis question based on the relationship between the gestation period of a pregnancy and see how the relationship between a child's birthweight and their mother's smoking-status are intertwined.

# Basic Analysis

## Data Processing and Summaries

### Methods

In order to analyze our data, we wanted to make sure that our data was clean, and was able to have analysis performed on it. In order to do this, we looked through the data to identify if there were any inconsistencies that we wanted to catch and either fix or get rid of. One such inconsistency was included when we went to check the data types for the second part of the survey.

```{r, echo = FALSE}
survey_p1 <- read.table("videodata.txt", header = TRUE)
survey_p2 <- read.table("videoMultiple.txt", header = TRUE)
```

Through this, we noticed that while the first part of the survey all contained numeric types, which was to be expected, the second part of the survey contained two non-numeric columns, 'other' and 'other2', both of which were not supposed to be included in the second part of the survey. In order to clean the data up, we removed these two columns.

```{r}
survey_p2 <- survey_p2[, !(names(survey_p2) %in% c("other", "other2"))]
all(sapply(survey_p2, is.numeric))
```

Furthermore, in order to clean up the data and keep it consistent, we wanted to combine our data into one data frame. By doing this, we are using the assumption that each row in 'survey_p1' is the same person that was in the same row in 'survey_p2', meaning that they are the same person. Additionally, we also got rid of rows that contained NA values, just to make sure we got rid of inconsistent data, because that could mess up our survey. From this, we noticed that we have 87 rows of data left, which means that 4 of our rows had NA values.

```{r}
combined_table <- cbind(survey_p1, survey_p2)
cleaned_df <- na.omit(combined_table)
dim(cleaned_df)
```

We also noted down the types of variables that were present in our data, since many were binary, ordinal, nominal, and more. We also graphed out histograms of the variables in the two surveys to see if we could identify any outliers, but since responses that were left unanswered or were improperly answered were coded as 99, there were no such outliers. Therefore, we went with the assumption that there were no outliers in the dataset, since they were all coded as 99 and could be filtered out later.

## Question 1: Estimate of Students who played a Video Game

### Methods

In order to provide a solid estimation of the amount of people who played a video game in the week prior to the survey, let's filter the amount of people who had over 0 hours last week as well as filter out those who didn't respond correctly or did not answer the question (99)

```{r, echo = FALSE}
n_played <- nrow(cleaned_df[cleaned_df$time > 0 | cleaned_df$time == 99, ])
n_total <- nrow(cleaned_df)

point_estimate_fraction <- n_played / n_total
print(paste("Point Estimate: ", round(point_estimate_fraction, 4)))
```

Furthermore, in order to get a more concrete range for the true measurement of this estimate, let's take a 95% confidence interval and get an interval estimate for the true population proportion who played a video game during an exam week.

```{r, echo = FALSE}
confidence_level = 0.95
z <- qnorm((1 + confidence_level) / 2)

se <- sqrt(point_estimate_fraction * (1 - point_estimate_fraction) / n_total)

lower_interval_estimate_fraction <- point_estimate_fraction - z * se
upper_interval_estimate_fraction <- point_estimate_fraction + z * se
print(paste("95% Confidence Interval: [", round(lower_interval_estimate_fraction, 4), ", ", round(upper_interval_estimate_fraction, 4), "]", sep = ""))
```

### Analysis

Our examination of video game engagement among UC Berkeley Statistics students during the Fall 1994 semester revealed that 36.78% of surveyed students reported playing video games in the week following their second examination. The 95% confidence interval for this proportion ranges from 26.65% to 46.91%, indicating the true population parameter lies within this range with 95% confidence.

Key analytical findings include:

-   The point estimate of 36.78% represents a substantial portion of the student population engaging in gaming activities in an academically intense period.
-   The confidence interval width of \~20% suggests a high variability amongst students in terms of gaming behavior.
-   The timing of the survey, during an exam week, provides context for interpreting these gaming patterns.

### Conclusions

Based on our analysis, we can draw several significant conclusions:

-   Video gaming was a common activity amongst Statistics students, even in a academically intense time. Our confidence interval shows us that at minimum, 25% of the student population was engaged in gaming activities during the survey period.
-   Video games were played by a significant amount of people in the Statistics course, yet our wide confidence interval suggests that there is a lot of variability amongst the people in the course, possibily suggesting that difference populations of students would have a different estimate about the percentage of students who played video games regularly.
-   The percentage found from the data indicates that gaming was a prevalent hobby even in the mid-1990s, and can perhaps provide insight into student gaming behavior into the future, as perhaps it has become even more significant as time has passed and gaming has become easier to access for everyone.

## Question 2

### Methods

In order to compare the amount of time spent playing video games during the exam week versus a normal week, let's analyze what we need to do. First, we should find the amount of time the students spent playing video games, which we can do by creating a summary of the 'time' column in our cleaned dataframe.

```{r, echo = FALSE}
actual_values = cleaned_df[cleaned_df$time != 99 & cleaned_df$freq != 99, ]
avg_time <- tapply(actual_values$time, actual_values$freq, mean, na.rm = TRUE)
median_time <- tapply(actual_values$time, actual_values$freq, median, na.rm = TRUE)
count <- table(actual_values$freq)

summary <- data.frame(
    frequency = names(avg_time),
    avg_time = as.vector(avg_time),
    median_time = as.vector(median_time),
    count = as.vector(count)
)
summary
```

In order to filter for the fact that the week was an exam week, let's make the assumption that many students that were studying for the exam were not playing games that week. In order to account for this, we filtered out students who played 0 hours of video games in the exam week. The reason we made this assumption is that it would mostly affect those that normally play daily or weekly, as compared to monthly or semesterly. If our assumption is that those who play monthly and semesterly would probably not even play, or play very little during an exam week, their distributions should remain relatively similar.

```{r, echo = FALSE}
exam_adjusted_df <- actual_values[actual_values$time != 0, ]
avg_time_adj <- tapply(exam_adjusted_df$time, exam_adjusted_df$freq, mean, na.rm = TRUE)
median_time_adj <- tapply(exam_adjusted_df$time, exam_adjusted_df$freq, median, na.rm = TRUE)
count_adj <- table(exam_adjusted_df$freq)

exam_adj_summary <- data.frame(
    frequency = names(avg_time_adj),
    avg_time = as.vector(avg_time_adj),
    median_time = as.vector(median_time_adj),
    count = as.vector(count_adj)
)

exam_adj_summary
```

Now, let's use a boxplot to compare the two distributions, between students playing video games during exam week and those who didn't.

```{r, echo = FALSE}
par(mfrow = c(1, 2), # 1 row, 2 columns
    mar = c(4, 4, 3, 1)) # Adjust margins (bottom, left, top, right)

boxplot(time ~ freq,
        data = actual_values,
        xlab = "",
        ylab = "Hours Played",
        main = "Hours During Exam Week",
        col = "#7A2048",
        cex.main = 0.9,    # Reduce title size
        cex.lab = 0.8,     # Reduce label size
        cex.axis = 0.8)    # Reduce axis text size

boxplot(time ~ freq, 
        data = exam_adjusted_df,
        xlab = "",
        ylab = "Hours Played",
        main = "Overall Hours Played",
        col = "#408EC6",
        cex.main = 0.9,
        cex.lab = 0.8,
        cex.axis = 0.8)

mtext("Frequency: 1=Daily, 2=Weekly, 3=Monthly, 4=Semesterly", 
      side = 1, 
      line = -1, 
      outer = TRUE,
      cex = 0.7)

par(mfrow = c(1, 1))
```

### Analysis

Looking through these two boxplots and their data summaries, there is an obvious difference, especially for students with a daily or weekly frequency of play. For instance, our adjusted comparison shows that those who played ('freq' = 1) daily during an exam week typically had a lower amount of hours played, with a 1.5 hour difference between our exam week data and our filtered data. Similarly, our boxplot also shows a difference in the interquartile range between the two datasets for those who played daily, as during a normal week, students were more likely to play more and had a wider variety of playtimes, which can be inferred from the two box plots. A similar comparison can be made from students who played weekly ('freq' = 2). There's a \~0.4 hour increase in normal weeks versus the exam week. Another interesting observation is that the adjusted data seems to have a smaller interquartile range compared to it's original exam week data, somewhat implying that those who play weekly usually play a more set amount of hours that usually doesn't diverge. Frequencies 3 and 4 don't have a large difference, just due to the nature of their descriptions, since most students in these categories would probably play very little to none already. If someone only plays games monthly or semesterly, then they are less likely to have major differences during an exam week versus a normal week.

### Conclusions

Overall, the fact that there was an exam in the week prior to the survey tells us this:

-   On average, students played less hours than they normally would on a week without an exam.
-   Those who reported that they play daily or weekly typically have the largest difference between their average hours played during an exam versus a normal week, with around a \~1.5 hour difference for those who play daily and a \~0.45 hour difference with those who play weekly.
-   Those who reported that they play monthly or semesterly have small or negligible differences between their average hours played due to the nature and scarcity of their data, along with the assumption that we made when filtering.

## Question 3

### Methods

The point estimate for the average amount of time spent playing video games in the week prior to the survey is simply the sample mean. We will also calculate the standard error (SE) to represent the expected variability of our sample mean from the true population mean of time spent playing video games. This SE will also be used to construct our 95% confidence interval. The SE formula must use the **population correction factor** because we are sampling **without replacement** from a relatively small population of 314.

$$SE = {σ \over \sqrt{n}} \times \sqrt{N-n \over N - 1}$$

```{r q3-methods, echo = FALSE}
point_estimate_average <- mean(survey_p1$time, na.rm=TRUE)
N <- 314
n <- length(survey_p1$time)

sample_sd <- sd(survey_p1$time, na.rm = TRUE)
pop_correction_factor = sqrt((N - n) / (N - 1))
standard_error <- (sample_sd / sqrt(n)) * pop_correction_factor

print(paste("point_estimate_average:", point_estimate_average))
print(paste("Standard Error:", standard_error))
```

Using the point estimate and standard error (in addition to an assumption of normality), we construct the 95% Confidence Interval.

```{r, echo = FALSE}
alpha <- 0.05
z_value <- qnorm(1 - alpha / 2)

lower_interval_estimate_average <- point_estimate_average - z_value * standard_error
upper_interval_estimate_average <- point_estimate_average + z_value * standard_error

print(paste("lower_interval_estimate_average:", lower_interval_estimate_average))
print(paste("upper_interval_estimate_average:", upper_interval_estimate_average))
```

```{r q3-analysis, echo = FALSE}
library(boot)

# Calculate the sample mean for each bootstrapped sample
bootstrap_mean <- function(data, indices) {
  return(mean(data[indices], na.rm = TRUE))
}

# Perform bootstrapping with 1000 iterations
bootstrap_results <- boot(survey_p1$time, bootstrap_mean, R = 1000)
bootstrap_means <- bootstrap_results$t

bootstrap_ci <- boot.ci(bootstrap_results, type = "perc")

# Extract lower and upper bounds of the 95% Bootstrap CI
lower_bound_bootstrap <- bootstrap_ci$percent[4]
upper_bound_bootstrap <- bootstrap_ci$percent[5]

hist(bootstrap_means, main = "Bootstrap Sample Means with 95% CIs", 
     xlab = "Sample Mean Time Spent", 
     col = "lightblue", 
     border = "black", 
     probability = TRUE)

# Add vertical lines for the confidence intervals
abline(v = lower_bound_bootstrap, col = "red", lwd = 2, lty = 2)  # Lower CI bound
abline(v = upper_bound_bootstrap, col = "red", lwd = 2, lty = 2)  # Upper CI bound
abline(v = lower_interval_estimate_average, col = "blue", lwd = 2, lty = 1)
abline(v = upper_interval_estimate_average, col = "blue", lwd = 2, lty = 1)


legend("topright", legend = c("Lower Bootstrap CI", "Upper Bootstrap CI", "Lower 95% CI", "Upper 95% CI"),
       col = c("red", "red", "blue", "blue"), lty = c(2, 2, 1, 1), lwd = 2)
```

### Analysis

### Conclusions

Your conclusions for Question 3.

## Question 4

### Methods

```{r q4-methods}
# Your R code for methods related to Question 4
```

### Analysis

```{r q4-analysis}
# Your R code for analysis related to Question 4
```

### Conclusions

Your conclusions for Question 4.

# Advanced Analysis

Our advanced analysis focuses on the intersectionality between people that like video games and which types of video games they prefer. By doing this, we can see the most popular types of video games that these students prefer, along with the average amount of time they play video games a week, potentially showing us which games people spent the most time on.

### Methods

In order to do this, we filtered the data. It's important to note that we ignored people who skipped this question, because those aren't the people we want to analyze. We went with the assumption that those who put all 0s in each of the columns that corresponded to the game type, because presumably if someone didn't like games or haven't played it, they wouldn't know the genres and skip.

```{r, echo = FALSE}
video_games_data <- cleaned_df[!(cleaned_df$action == 0 & cleaned_df$adv == 0 & cleaned_df$sim == 0 & cleaned_df$sport == 0 & cleaned_df$strategy == 0), ]
dim(video_games_data)
```

From this, we can see that we have 75 respondents that still enjoy games, which we can further filter out. WE can do this by capturing the most popular video game genres from this data, while also comparing the amount of time people spent playing those games.

```{r, echo = FALSE}
freq_table <- colSums(video_games_data[, c("action", "adv", "sim", "sport", "strategy")] == 1)
action_time <- sum(cleaned_df$time[cleaned_df$action == 1], na.rm = TRUE)
adv_time <- sum(cleaned_df$time[cleaned_df$adv == 1], na.rm = TRUE)
sim_time <- sum(cleaned_df$time[cleaned_df$sim == 1], na.rm = TRUE)
sport_time <- sum(cleaned_df$time[cleaned_df$sport == 1], na.rm = TRUE)
strategy_time <- sum(cleaned_df$time[cleaned_df$strategy == 1], na.rm = TRUE)

summed_times <- c(
    action_time,
    adv_time,
    sim_time,
    sport_time,
    strategy_time
)
names(summed_times) <- c("action", "adv", "sim", "sport", "strategy")

# Set up the plotting layout for side by side graphs
par(mfrow = c(1, 2), 
   mar = c(6, 4, 3, 1))  # Increased bottom margin for rotated labels

# First barplot
barplot(freq_table, 
       main = "Genre Popularity",    # Shortened title
       xlab = "Genre",                    # Removed xlabel since labels are rotated
       ylab = "Frequency", 
       col = "#B85042",
       las = 2,                      # Rotate x-axis labels
       cex.main = 0.9,              # Reduce title size
       cex.axis = 0.8,              # Reduce axis text size
       cex.names = 0.8)             # Reduce bar labels size

# Second barplot
barplot(summed_times,
       main = "Time by Category",    # Shortened title
       xlab = "Genre",                    # Removed xlabel since labels are rotated
       ylab = "Total Time", 
       col = "#A7BEAE",
       las = 2,
       cex.main = 0.9,
       cex.axis = 0.8,
       cex.names = 0.8)

# Reset par to default after plotting
par(mfrow = c(1, 1))
```

### Analysis

Our two graphs, especially when put next to each other, show us another interesting detail. Although strategy was the most popular game genre chosen by people, with the action and sport genres falling slightly behind, when we look through the total time spent playing each game, action was the highest, with sport and then strategy falling behind. This means that there's a decent chance that the people who play strategy games don't typically play the game for a longer time, while those who played action and sports games play for longer durations. On another note, sim was the least popular genre of game in the survey, and that pattern still shows in the total time spent. People who mentioned they like simulation games spent very little time actually playing them, leading us to believe that those who play these simulation games either don't play them very often or play them for short periods of time compared to their peers who played action or sport games.

### Conclusions

Our conclusions for this advanced analysis show us that although a video game genre like 'strategy' could perhaps be the most accessible, it's not necessarily the most played time-wise. While 'action' and 'sport' genres were not as popular as 'strategy' games in terms of total picks, the students who played these games far exceeded the play-time of students who played 'strategy' games.

It's also important to note that this isn't conclusive. Firstly, there's inherent bias because this survey was taken during an exam week, likely leading to students playing less than they normally would. Additionally, the way we filtered our data may be potentially flawed, as students were allowed to choose up to 3 of their favorite genres, not just one. This means that our graph of total time spent on each category is layered and can be duplicated, because if a student likes to play multiple genres of games, they are stacked on top of their respective genres, potentially leading to more visible and exaggerated graphs than what would normally be. However, even with that discrepancy, we still believe that these two graphs show us concrete differences in many of the genres and how students viewed the genres differently, both in terms of popularity as well as personal enjoyment.

# Conclusions and Discussion

## Summary of Findings

Reprise the questions and goals of the analysis stated in the introduction. Summarize the findings and compare them to the original goals.

## Discussion

Additional observations or details gleaned from the analysis section. Discuss relevance to the science and other studies, if applicable. Address data limitations. Raise new questions and suggest future work.
