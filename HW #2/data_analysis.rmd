---
title: "Gaming Patterns in Higher Education"
author: "Author 1 and Author 2"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Header

## Author Contributions

Kevin Wong: Did the data cleaning and preliminary analysis, as well as contributed to questions #1 and #2, along with doing the advanced data analysis.

Jeffrey Meredith: Contributed to additional data cleaning specific to the questions and analysis for questions 3, 4, and 5.

## Use of GPT

ChatGPT was used as a substitute for documentation for R. Since we were unfamiliar with R, we asked ChatGPT how to use R in certain methods in order to find and filter out conditions in the dataset. We additionally used GPT to analyze reasoning and to confirm what we thought was correct about the dataset, as well as to identify extra questions that could be answered for our advanced analysis.

# Introduction

The data provided is from a survey done at UC Berkeley for students enrolled in a statistics course in 1994. Out of an eligible 314 students, 91 students submitted eligible responses which will be the data used in this EDA. The data focuses on student's play time of video games, likes and dislikes of video games, and more. One important thing to note is that responses that were left unanswered or improperly answered were coded as 99, and students who had never played video games or expressed a strong dislike for them were instructed to skip many questions. Additionally, the survey was distributed into two parts, where the first part asks about variable data, while the second part focuses on attitude questions.

## Main Research Questions

1.  Provide an estimate for the fraction of students who played a video game in the week prior to the survey.

2.  Check to see how the amount of time spent playing video games in the week prior to the survey compares to the reported frequency of play (daily, weekly, etc). How might the fact that there was an exam in the week prior to the survey affect your previous estimates and this comparison?

3.  Provide a point estimate and an interval estimate for the average amount of time spent playing video games in the week prior to the survey. Keep in mind the overall shape of the sample distribution. A simulation study may help determine the appropriateness of an interval estimate.

4.  Consider the attitude questions. In general, do you think the students enjoy playing video games? If you had to make a short list of the most important reasons why students like/dislike video games, what would you put on the list? Don’t forget that those students who say that they have never played video games or do not at all like video games are asked to skip over some of these questions. So, there may be many nonrespondents to the questions as to whether they think video games are educational, where they play video games, etc.

5.  Look for the differences between those who like to play video games and those who don’t. To do this, use the questions in the last part of the survey, and make comparisons between male and female students, those who work for pay and those who don’t, those who own a computer and those who don’t. Graphical display and cross-tabulations are particularly helpful in making these kinds of comparisons. Also, you may want to collapse the range of responses to a question down to two or three possibilities before making these comparisons.

6.  Further investigate the grade that students expect in the course. How does it match the target distribution used in grade assignment of 20% A’s, 30% B’s, 40% C’s and 10% D’s or lower? If the nonrespondents were failing students who no longer bothered to come to the discussion section, would this change the picture?

## Outline

The remainder of the report will go through a basic analysis of the data, including our cleaning methods, basic analysis on various variables in the study, and more. Additionally, we will analysis the questions posed above, along with the conclusions that we came up with in our data. We will also pose an advanced analysis question based on the relationship between the gestation period of a pregnancy and see how the relationship between a child's birthweight and their mother's smoking-status are intertwined.

# Basic Analysis

## Data Processing and Summaries

### Methods

In order to analyze our data, we wanted to make sure that our data was clean, and was able to have analysis performed on it. In order to do this, we looked through the data to identify if there were any inconsistencies that we wanted to catch and either fix or get rid of. One such inconsistency was included when we went to check the data types for the second part of the survey.

```{r, echo = FALSE}
survey_p1 <- read.table("videodata.txt", header = TRUE)
survey_p2 <- read.table("videoMultiple.txt", header = TRUE)
```

Through this, we noticed that while the first part of the survey all contained numeric types, which was to be expected, the second part of the survey contained two non-numeric columns, 'other' and 'other2', both of which were not supposed to be included in the second part of the survey. In order to clean the data up, we removed these two columns.

```{r}
survey_p2 <- survey_p2[, !(names(survey_p2) %in% c("other", "other2"))]
all(sapply(survey_p2, is.numeric))
```

Furthermore, in order to clean up the data and keep it consistent, we wanted to combine our data into one data frame. By doing this, we are using the assumption that each row in 'survey_p1' is the same person that was in the same row in 'survey_p2', meaning that they are the same person. Additionally, we also got rid of rows that contained NA values, just to make sure we got rid of inconsistent data, because that could mess up our survey. From this, we noticed that we have 87 rows of data left, which means that 4 of our rows had NA values.

```{r}
combined_table <- cbind(survey_p1, survey_p2)
cleaned_df <- na.omit(combined_table)
dim(cleaned_df)
```

We also noted down the types of variables that were present in our data, since many were binary, ordinal, nominal, and more. We also graphed out histograms of the variables in the two surveys to see if we could identify any outliers, but since responses that were left unanswered or were improperly answered were coded as 99, there were no such outliers. Therefore, we went with the assumption that there were no outliers in the dataset, since they were all coded as 99 and could be filtered out later.

## Question 1: Estimate of Students who played a Video Game

### Methods

In order to provide a solid estimation of the amount of people who played a video game in the week prior to the survey, let's filter the amount of people who had over 0 hours last week as well as filter out those who didn't respond correctly or did not answer the question (99)

```{r, echo = FALSE}
n_played <- nrow(cleaned_df[cleaned_df$time > 0 | cleaned_df$time == 99, ])
n_total <- nrow(cleaned_df)

point_estimate_fraction <- n_played / n_total
print(paste("Point Estimate: ", round(point_estimate_fraction, 4)))
```

Furthermore, in order to get a more concrete range for the true measurement of this estimate, let's take a 95% confidence interval and get an interval estimate for the true population proportion who played a video game during an exam week.

```{r, echo = FALSE}
confidence_level = 0.95
z <- qnorm((1 + confidence_level) / 2)

se <- sqrt(point_estimate_fraction * (1 - point_estimate_fraction) / n_total)

lower_interval_estimate_fraction <- point_estimate_fraction - z * se
upper_interval_estimate_fraction <- point_estimate_fraction + z * se
print(paste("95% Confidence Interval: [", round(lower_interval_estimate_fraction, 4), ", ", round(upper_interval_estimate_fraction, 4), "]", sep = ""))
```

### Analysis

Our examination of video game engagement among UC Berkeley Statistics students during the Fall 1994 semester revealed that 36.78% of surveyed students reported playing video games in the week following their second examination. The 95% confidence interval for this proportion ranges from 26.65% to 46.91%, indicating the true population parameter lies within this range with 95% confidence.

Key analytical findings include:

-   The point estimate of 36.78% represents a substantial portion of the student population engaging in gaming activities in an academically intense period.
-   The confidence interval width of \~20% suggests a high variability amongst students in terms of gaming behavior.
-   The timing of the survey, during an exam week, provides context for interpreting these gaming patterns.

### Conclusions

Based on our analysis, we can draw several significant conclusions:

-   Video gaming was a common activity amongst Statistics students, even in a academically intense time. Our confidence interval shows us that at minimum, 25% of the student population was engaged in gaming activities during the survey period.
-   Video games were played by a significant amount of people in the Statistics course, yet our wide confidence interval suggests that there is a lot of variability amongst the people in the course, possibily suggesting that difference populations of students would have a different estimate about the percentage of students who played video games regularly.
-   The percentage found from the data indicates that gaming was a prevalent hobby even in the mid-1990s, and can perhaps provide insight into student gaming behavior into the future, as perhaps it has become even more significant as time has passed and gaming has become easier to access for everyone.

## Question 2: Find Effect of Exam Week on Time Spent Playing

### Methods

In order to compare the amount of time spent playing video games during the exam week versus a normal week, let's analyze what we need to do. First, we should find the amount of time the students spent playing video games, which we can do by creating a summary of the 'time' column in our cleaned dataframe.

```{r, echo = FALSE}
actual_values = cleaned_df[cleaned_df$time != 99 & cleaned_df$freq != 99, ]
avg_time <- tapply(actual_values$time, actual_values$freq, mean, na.rm = TRUE)
median_time <- tapply(actual_values$time, actual_values$freq, median, na.rm = TRUE)
count <- table(actual_values$freq)

summary <- data.frame(
    frequency = names(avg_time),
    avg_time = as.vector(avg_time),
    median_time = as.vector(median_time),
    count = as.vector(count)
)
summary
```

In order to filter for the fact that the week was an exam week, let's make the assumption that many students that were studying for the exam were not playing games that week. In order to account for this, we filtered out students who played 0 hours of video games in the exam week. The reason we made this assumption is that it would mostly affect those that normally play daily or weekly, as compared to monthly or semesterly. If our assumption is that those who play monthly and semesterly would probably not even play, or play very little during an exam week, their distributions should remain relatively similar.

```{r, echo = FALSE}
exam_adjusted_df <- actual_values[actual_values$time != 0, ]
avg_time_adj <- tapply(exam_adjusted_df$time, exam_adjusted_df$freq, mean, na.rm = TRUE)
median_time_adj <- tapply(exam_adjusted_df$time, exam_adjusted_df$freq, median, na.rm = TRUE)
count_adj <- table(exam_adjusted_df$freq)

exam_adj_summary <- data.frame(
    frequency = names(avg_time_adj),
    avg_time = as.vector(avg_time_adj),
    median_time = as.vector(median_time_adj),
    count = as.vector(count_adj)
)

exam_adj_summary
```

Now, let's use a boxplot to compare the two distributions, between students playing video games during exam week and those who didn't.

```{r, echo = FALSE}
par(mfrow = c(1, 2), # 1 row, 2 columns
    mar = c(4, 4, 3, 1)) # Adjust margins (bottom, left, top, right)

boxplot(time ~ freq,
        data = actual_values,
        xlab = "",
        ylab = "Hours Played",
        main = "Hours During Exam Week",
        col = "#7A2048",
        cex.main = 0.9,    # Reduce title size
        cex.lab = 0.8,     # Reduce label size
        cex.axis = 0.8)    # Reduce axis text size

boxplot(time ~ freq, 
        data = exam_adjusted_df,
        xlab = "",
        ylab = "Hours Played",
        main = "Overall Hours Played",
        col = "#408EC6",
        cex.main = 0.9,
        cex.lab = 0.8,
        cex.axis = 0.8)

mtext("Frequency: 1=Daily, 2=Weekly, 3=Monthly, 4=Semesterly", 
      side = 1, 
      line = -1, 
      outer = TRUE,
      cex = 0.7)

par(mfrow = c(1, 1))
```

### Analysis

Looking through these two boxplots and their data summaries, there is an obvious difference, especially for students with a daily or weekly frequency of play. For instance, our adjusted comparison shows that those who played ('freq' = 1) daily during an exam week typically had a lower amount of hours played, with a 1.5 hour difference between our exam week data and our filtered data. Similarly, our boxplot also shows a difference in the interquartile range between the two datasets for those who played daily, as during a normal week, students were more likely to play more and had a wider variety of playtimes, which can be inferred from the two box plots. A similar comparison can be made from students who played weekly ('freq' = 2). There's a \~0.4 hour increase in normal weeks versus the exam week. Another interesting observation is that the adjusted data seems to have a smaller interquartile range compared to it's original exam week data, somewhat implying that those who play weekly usually play a more set amount of hours that usually doesn't diverge. Frequencies 3 and 4 don't have a large difference, just due to the nature of their descriptions, since most students in these categories would probably play very little to none already. If someone only plays games monthly or semesterly, then they are less likely to have major differences during an exam week versus a normal week.

### Conclusions

Overall, the fact that there was an exam in the week prior to the survey tells us this:

-   On average, students played less hours than they normally would on a week without an exam.
-   Those who reported that they play daily or weekly typically have the largest difference between their average hours played during an exam versus a normal week, with around a \~1.5 hour difference for those who play daily and a \~0.45 hour difference with those who play weekly.
-   Those who reported that they play monthly or semesterly have small or negligible differences between their average hours played due to the nature and scarcity of their data, along with the assumption that we made when filtering.

## Question 3: Estimate Average Time Spent Playing

### Methods

The point estimate for the average amount of time spent playing video games in the week prior to the survey is simply the sample mean. We will also calculate the standard error (SE) to represent the expected variability of our sample mean from the true population mean of time spent playing video games. This SE will also be used to construct our 95% confidence interval. The SE formula must use the **population correction factor** because we are sampling **without replacement** from a relatively small population of 314.

$$SE = {σ \over \sqrt{n}} \times \sqrt{N-n \over N - 1}$$

```{r q3-methods, echo = FALSE}
point_estimate_average <- mean(cleaned_df$time, na.rm=TRUE)
N <- 314
n <- length(cleaned_df$time)

sample_sd <- sd(cleaned_df$time, na.rm = TRUE)
pop_correction_factor = sqrt((N - n) / (N - 1))
standard_error <- (sample_sd / sqrt(n)) * pop_correction_factor

print(paste("point_estimate_average:", point_estimate_average))
print(paste("Standard Error:", standard_error))
```

Using the point estimate and standard error (in addition to an assumption of normality), we construct the 95% Confidence Interval.

```{r, echo = FALSE}
alpha <- 0.05
z_value <- qnorm(1 - alpha / 2)

lower_interval_estimate_average <- point_estimate_average - z_value * standard_error
upper_interval_estimate_average <- point_estimate_average + z_value * standard_error

print(paste("lower_interval_estimate_average:", lower_interval_estimate_average, "hours"))
print(paste("upper_interval_estimate_average:", upper_interval_estimate_average, "hours"))
```

To assess if our interval estimate is appropriate, we bootstrap 1000 sample means to estimate the sampling distribution. The mean and standard deviation of the bootstrap distribution are calculated.

```{r q3-analysis, echo = FALSE}
library(boot)

# Calculate the sample mean for each bootstrapped sample
bootstrap_mean <- function(data, indices) {
  return(mean(data[indices], na.rm = TRUE))
}

# Perform bootstrapping with 1000 iterations
bootstrap_results <- boot(cleaned_df$time, bootstrap_mean, R = 1000)
bootstrap_means <- bootstrap_results$t
bootstrap_mean <- mean(bootstrap_means)
bootstrap_sd <- sd(bootstrap_means)

print(paste("Mean of bootstrap distribution:", bootstrap_mean, "hours"))
print(paste("Standard Deviation of bootstrap distribution:", bootstrap_sd, "hours"))
```

Now, I construct a 95% bootstrap CI using the percentiles of my bootstrapped sample means and compare it to the earlier CI. If they are significantly different, the interval estimate may not be appropriate for this situation.

```{r, echo = FALSE}
bootstrap_ci <- boot.ci(bootstrap_results, type = "perc")

# Extract lower and upper bounds of the 95% Bootstrap CI
lower_bound_bootstrap <- bootstrap_ci$percent[4]
upper_bound_bootstrap <- bootstrap_ci$percent[5]

hist(bootstrap_means, main = "Bootstrap Sample Means with 95% CIs", 
     xlab = "Sample Mean Time Spent", 
     col = "lightblue", 
     border = "black", 
     probability = TRUE)

# Add vertical lines for the confidence intervals
abline(v = lower_bound_bootstrap, col = "red", lwd = 2, lty = 2)  # Lower CI bound
abline(v = upper_bound_bootstrap, col = "red", lwd = 2, lty = 2)  # Upper CI bound
abline(v = lower_interval_estimate_average, col = "blue", lwd = 2, lty = 1)
abline(v = upper_interval_estimate_average, col = "blue", lwd = 2, lty = 1)


legend("topright", legend = c("Lower Bootstrap CI", "Upper Bootstrap CI", "Lower 95% CI", "Upper 95% CI"),
       col = c("red", "red", "blue", "blue"), lty = c(2, 2, 1, 1), lwd = 2)
```

### Analysis

Our 95% CI for the average time spent playing video games by UC Berkeley students was constructed under an assumption of approximate normality. It tells us that we are 95% confident UC Berkeley students play video games an average of 0.59 to 1.90 hours per week.

We bootstrapped 1000 sample means to estimate the sampling distribution. This bootstrap distribution had a mean of **1.23** and a standard deviation of **0.39**, while our original sample had a mean of **1.24** and a standard error of **0.33**. Additionally, the bootstrap histogram reveals a right skew. The difference between the sample's standard error and the bootstrap distribution's standard deviation in addition to the right-skewed shape suggest that the underlying population may not be perfectly normal. The graph also reveals a difference between the 95% CI and the 95% Bootstrap CI. The bootstrap CI extends further to the right than the initial 95% CI.

### Conclusions

In conclusion, while our initial 95% confidence interval suggests that the true average time spent playing video games per week among UC Berkeley students is between 0.59 to 1.9 hours, there is evidence to suggest that this is not the most appropriate estimate to use. This is because the underlying sampling distribution of average play times might not be normal according to the shape of our bootstrap distribution. The variation in our bootstrap distribution is also noticeably greater than the standard error of our original sample, providing more evidence that the interval estimate is not appropriate.

## Question 4: Important Reasons for Liking/Disliking Video Games

### Methods

First, to get an idea of whether students generally like playing video games or not, we examine a bar plot of the "like" variable.

```{r q4-methods, echo = FALSE}
like_counts <- table(subset(cleaned_df, like != 99)$like)

# Plot the bar plot
like_counts_plot <- barplot(like_counts, 
        main = "Counts of Responses to 'Like to Play' Video Games", 
        xlab = "Response Category", 
        ylab = "Count of Students", 
        col = "lightblue", 
        border = "black", 
        names.arg = c("Never Played", "Very Much", "Somewhat", "Not Really", "Not At All"))

text(x = like_counts_plot, y = like_counts, label = like_counts, pos = 1, cex = 0.8, col = "red")
```

Additionally, we calculate the proportion of students surveyed that at least somewhat like playing video games.

```{r, echo = FALSE}
total_students <- length(cleaned_df$like[cleaned_df$like != 99])
students_like <- length(cleaned_df$like[cleaned_df$like == 2 | cleaned_df$like == 3])

proportion_like <- students_like / total_students
print(paste("Proportion of students in sample who at least somewhat like video games:", proportion_like))
```

Now, to find the most influential reasons for why students like or dislike playing video games, we use a bar plot to visualize the frequency of each reason.

```{r, echo = FALSE}
reason_frequencies <- colSums(cleaned_df[, !names(cleaned_df) %in% c("action","adv","sim","sport","strategy")])

bar_colors <- c("relax" = "lightblue", 
                "coord" = "lightblue", 
                "challenge" = "lightblue", 
                "master" = "lightblue", 
                "bored" = "lightblue", 
                "graphic" = "lightblue",
                "time" = "red",
                "frust" = "red",
                "lonely" = "red",
                "rules" = "red",
                "cost" = "red",
                "boring" = "red",
                "friends" = "red",
                "point" = "red")

reason_plot <- barplot(reason_frequencies, 
        main = "Frequencies of Reasons for Liking/Disliking Video Games",
        ylab = "Frequency", 
        col = bar_colors[names(reason_frequencies)], 
        border = "black", 
        las = 2)
text(x = reason_plot, y = reason_frequencies, label = reason_frequencies, pos = 1, cex = 0.8, col = "black")
```

The most important reason for why students like video games is for relaxation. The most important reasons why students don't like video games are that they're time-consuming, costly, and pointless.

```{r, echo = FALSE}
reasons_for_likeliness <- c("relax", "time", "cost", "point")
print("Reasons for Like/Dislike Video Games:")
print(reasons_for_likeliness)
```

### Analysis

Examining the initial bar plot of responses to the "Like to Play" question reveals that a majority of students surveyed at UC Berkeley like to play video games at least "somewhat". Only 1 student had never played video games and only 7 don't enjoy them at all. **76.7%** of students surveyed enjoyed playing video games at least somewhat. The second bar plot displayed in this section shows the counts of reasons for liking/disliking video games as well as a color code representing whether the reason is positive or negative. The most common reason for liking video games is "Relaxation" with a response count of 58. The most common reason for disliking video games is "time consuming". The next most common reasons given are "Cost", "Pointless", and "Mastery".

### Conclusions

In conclusion, the responses to the "Like to Play" question show that UC Berkeley students like to play video games in general, with **76.7%** of students responding with either "somewhat" or "very much". The most important factors for liking or disliking video games are "Relaxation", "Time Consuming", "Cost", and "Pointless".

## Question 5: Compare Different Types of Students and Why They Play Games

### Methods

To understand the differences between those who like to play video games and those who don't, we first collapse the range of responses to the last questions into 2 or 3 responses per question rather than 6 or 7. The responses to the question "Why do you play video games?" were placed into 2 categories: "Entertainment" and "Mental Engagement". The responses to the question "Why don't you like playing video games?" were placed into 3 categories: "Difficulty", "Low Priority", and "Isolation".

```{r, echo = FALSE}
clean_p2 <- cleaned_df

clean_p2$Entertainment <- clean_p2$graphic | clean_p2$relax | clean_p2$bored
clean_p2$Mental_Engagement <- clean_p2$coord | clean_p2$challenge | clean_p2$master
clean_p2$Difficulty <- clean_p2$frust | clean_p2$rules
clean_p2$Low_Priority <- clean_p2$time | clean_p2$cost | clean_p2$boring | clean_p2$point
clean_p2$Isolation <- clean_p2$lonely | clean_p2$friends

clean_p2 <- clean_p2[, c("sex", "work", "own", "Entertainment","Mental_Engagement","Difficulty","Low_Priority","Isolation")]
clean_p2[clean_p2 == 99] <- NA
clean_p2$work <- clean_p2$work > 0
clean_p2 <- na.omit(clean_p2)
```

Next, we make cross-tabulations to show how various factors for liking or disliking video games change between different groups of people. The cross-tabulations showing the most significant difference between groups are displayed below.

```{r, echo = FALSE}
sex_cross_tab <- table(clean_p2$Entertainment, clean_p2$sex)
dimnames(sex_cross_tab) <- list(
  "Entertainment" = c("No", "Yes"),
  "Sex" = c("Female", "Male")
)

work_cross_tab <- table(clean_p2$Mental_Engagement, clean_p2$work)
dimnames(work_cross_tab) <- list(
  "Mental Engagement" = c("No", "Yes"),
  "Works" = c("Doesn't Work", "Works")
)

own_cross_tab <- table(clean_p2$Entertainment, clean_p2$own)
dimnames(own_cross_tab) <- list(
  "Entertainment" = c("No", "Yes"),
  "Owns PC" = c("Doesn't Own", "Owns")
)

cat("Cross-Tabulation: Sex vs Entertainment\n\n")
print(sex_cross_tab)

cat("\n\n\nCross-Tabulation: Works vs Mental Engagement\n\n")
print(work_cross_tab)

cat("\n\n\nCross-Tabulation: Owns PC vs Entertainment\n\n")
print(own_cross_tab)
```

To analyze these comparisons further, we produce grouped bar plots.

```{r, echo = FALSE}
barplot(sex_cross_tab, beside = TRUE, 
        col = c("red", "skyblue"),
        main = "Gender vs Enjoys Entertainment",
        xlab = "Gender", 
        ylab = "Count")
legend("topright", legend = rownames(sex_cross_tab), fill = c("red", "skyblue"), title = "Enjoys Entertainment", inset = c(0.3, 0), cex=0.7)

barplot(work_cross_tab, beside = TRUE,
        col = c("red", "skyblue"),
        main = "Works vs Enjoys Mental Challenge",
        xlab = "Employment",
        ylab = "Count")
legend("topright", legend = rownames(work_cross_tab), fill = c("red", "skyblue"), title = "Enjoys Mental Challenge", inset = c(0.35, 0), cex=0.7)

barplot(own_cross_tab, beside = TRUE,
        col = c("red", "skyblue"),
        main = "Owns PC vs Enjoys Entertainment",
        ylim = c(0, 60),
        xlab = "PC Ownership",
        ylab = "Count")
legend("topright", legend = rownames(own_cross_tab), fill = c("red", "skyblue"), title = "Enjoys Entertainment", inset = c(0.35, 0), cex=0.7)
```

### Analysis

Looking at our notable cross-tabulations reveals that, of those that responded to survey part 2, **70% of females** said they like video games for entertainment reasons in comparison to **80% of males**. This could suggest that male students are more likely to play video games for entertainment. Looking at the second cross-tabulation reveals that **55% of students who work** for pay enjoy video games for mental engagement/stimulation, while only **32% of students who don't work** enjoy games for such reasons. This could suggest that students who work enjoy the mental engagement aspect of video games more. Finally, the third cross-tabulation reveals that **74% of students who own a PC** enjoy the entertainment aspect of video games while **82% of students who don't own a PC** enjoy the entertainment aspect. This insight may be surprising, but further analysis is needed to make a general statement about the population of college students. The rest of the cross-tabulations revealed much smaller differences between groups, suggesting that factors like gender, employment, and PC ownership don't strongly impact sentiments toward video games being difficult, isolating, and low priority.

### Conclusion

In conclusion, the strongest contrast between groups of students detected in the survey was between students who work and those who don't. A significantly larger proportion of students who work enjoyed video games for mental engagement purposes, with **55%** for those who work and only **32%** for those who don't. The next strongest contrast is between males and females, with males being more likely to enjoy the entertainment of video games. Finally, students who own PC's in the survey were more likely to enjoy video games for entertainment than those who don't.

# Advanced Analysis

Our advanced analysis focuses on the intersectionality between people that like video games and which types of video games they prefer. By doing this, we can see the most popular types of video games that these students prefer, along with the average amount of time they play video games a week, potentially showing us which games people spent the most time on.

### Methods

In order to do this, we filtered the data. It's important to note that we ignored people who skipped this question, because those aren't the people we want to analyze. We went with the assumption that those who put all 0s in each of the columns that corresponded to the game type, because presumably if someone didn't like games or haven't played it, they wouldn't know the genres and skip.

```{r, echo = FALSE}
video_games_data <- cleaned_df[!(cleaned_df$action == 0 & cleaned_df$adv == 0 & cleaned_df$sim == 0 & cleaned_df$sport == 0 & cleaned_df$strategy == 0), ]
dim(video_games_data)
```

From this, we can see that we have 75 respondents that still enjoy games, which we can further filter out. WE can do this by capturing the most popular video game genres from this data, while also comparing the amount of time people spent playing those games.

```{r, echo = FALSE}
freq_table <- colSums(video_games_data[, c("action", "adv", "sim", "sport", "strategy")] == 1)
action_time <- sum(cleaned_df$time[cleaned_df$action == 1], na.rm = TRUE)
adv_time <- sum(cleaned_df$time[cleaned_df$adv == 1], na.rm = TRUE)
sim_time <- sum(cleaned_df$time[cleaned_df$sim == 1], na.rm = TRUE)
sport_time <- sum(cleaned_df$time[cleaned_df$sport == 1], na.rm = TRUE)
strategy_time <- sum(cleaned_df$time[cleaned_df$strategy == 1], na.rm = TRUE)

summed_times <- c(
    action_time,
    adv_time,
    sim_time,
    sport_time,
    strategy_time
)
names(summed_times) <- c("action", "adv", "sim", "sport", "strategy")

# Set up the plotting layout for side by side graphs
par(mfrow = c(1, 2), 
   mar = c(6, 4, 3, 1))  # Increased bottom margin for rotated labels

# First barplot
barplot(freq_table, 
       main = "Genre Popularity",    # Shortened title
       xlab = "Genre",                    # Removed xlabel since labels are rotated
       ylab = "Frequency", 
       col = "#B85042",
       las = 2,                      # Rotate x-axis labels
       cex.main = 0.9,              # Reduce title size
       cex.axis = 0.8,              # Reduce axis text size
       cex.names = 0.8)             # Reduce bar labels size

# Second barplot
barplot(summed_times,
       main = "Time by Category",    # Shortened title
       xlab = "Genre",                    # Removed xlabel since labels are rotated
       ylab = "Total Time", 
       col = "#A7BEAE",
       las = 2,
       cex.main = 0.9,
       cex.axis = 0.8,
       cex.names = 0.8)

# Reset par to default after plotting
par(mfrow = c(1, 1))
```

### Analysis

Our two graphs, especially when put next to each other, show us another interesting detail. Although strategy was the most popular game genre chosen by people, with the action and sport genres falling slightly behind, when we look through the total time spent playing each game, action was the highest, with sport and then strategy falling behind. This means that there's a decent chance that the people who play strategy games don't typically play the game for a longer time, while those who played action and sports games play for longer durations. On another note, sim was the least popular genre of game in the survey, and that pattern still shows in the total time spent. People who mentioned they like simulation games spent very little time actually playing them, leading us to believe that those who play these simulation games either don't play them very often or play them for short periods of time compared to their peers who played action or sport games.

### Conclusions

Our conclusions for this advanced analysis show us that although a video game genre like 'strategy' could perhaps be the most accessible, it's not necessarily the most played time-wise. While 'action' and 'sport' genres were not as popular as 'strategy' games in terms of total picks, the students who played these games far exceeded the play-time of students who played 'strategy' games.

It's also important to note that this isn't conclusive. Firstly, there's inherent bias because this survey was taken during an exam week, likely leading to students playing less than they normally would. Additionally, the way we filtered our data may be potentially flawed, as students were allowed to choose up to 3 of their favorite genres, not just one. This means that our graph of total time spent on each category is layered and can be duplicated, because if a student likes to play multiple genres of games, they are stacked on top of their respective genres, potentially leading to more visible and exaggerated graphs than what would normally be. However, even with that discrepancy, we still believe that these two graphs show us concrete differences in many of the genres and how students viewed the genres differently, both in terms of popularity as well as personal enjoyment.

# Conclusions and Discussion

## Summary of Findings

Reprise the questions and goals of the analysis stated in the introduction. Summarize the findings and compare them to the original goals.

## Discussion

Additional observations or details gleaned from the analysis section. Discuss relevance to the science and other studies, if applicable. Address data limitations. Raise new questions and suggest future work.
